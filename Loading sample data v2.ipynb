{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec17dd2f-4c5e-4cd8-b3fa-777bac0f85b3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load a dataframe from a SQL statement"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"select * from samples.nyctaxi.trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c70d5b6e-5e73-4bd6-aefb-2b7030f9a933",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Display the dataframe"
    }
   },
   "outputs": [],
   "source": [
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2569701-6c33-4400-b580-0c9bc6a5f29b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Print out the dataframe schema"
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2fe57af-21cb-44ac-87f2-7e085d19f738",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Display data types"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e87d51b5-2d1d-4325-9f6b-2b8c5390a7f6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Show rowcount"
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a28bd23-7f7f-4d3a-b0d6-187a0acaae1c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add a new column based on some logic"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df = df.withColumn(\"different_zip\", expr(\"CASE WHEN pickup_zip <> dropoff_zip THEN 'same_zip' ELSE 'different_zip' END\"))\n",
    "\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5cb5e93-8ad9-4c37-a651-7d2dbe5cc515",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a temp view"
    }
   },
   "outputs": [],
   "source": [
    "df.where(\"different_zip = 'same_zip'\").createOrReplaceTempView(\"tmp_same_zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c06a26f-55f9-40d4-83a9-0828832bb653",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read from that temp view into a new dataframe"
    }
   },
   "outputs": [],
   "source": [
    "df_same_zip = spark.sql(\"select * from tmp_same_zip\")\n",
    "df_same_zip.display()\n",
    "# on non-serverless compute you can do this, on serverless compute it's not supported\n",
    "# df_same_zip.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e64d4b87-d3bd-4418-a2be-62646bde675b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get record count"
    }
   },
   "outputs": [],
   "source": [
    "df_same_zip.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27ef9103-c062-4840-a450-64322fc9013b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use a Python F string to show variable in a string"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The view same_zip contains {df_same_zip.count()} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94807767-e6c8-49b9-a2fd-59a34783d98d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Querying the data with SQL"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select * from tmp_same_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4002d055-7e0e-46d1-b32d-d3b9ce8fc50a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use SQL to create a new table based on a SQL statement (think CETAS)"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table same_zip_agg\n",
    "as\n",
    "select  MIN(tpep_pickup_datetime) as min_pickup_date,\n",
    "        MAX(tpep_pickup_datetime) as max_pickup_date\n",
    "from tmp_same_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f138172e-a10e-4f3c-a458-cc1d86f748f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Query that new table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from same_zip_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "959bbbed-12b2-4d45-8360-0b7be85be9a1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rename a column in a dataframe"
    }
   },
   "outputs": [],
   "source": [
    "df_same_zip = df_same_zip.withColumnRenamed(\"different_zip\", \"long_distance\")\n",
    "df_same_zip.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe3d60b6-b2b5-48a6-975a-510948c37bd7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write a dataframe to a table"
    }
   },
   "outputs": [],
   "source": [
    "df_same_zip.write.mode(\"overwrite\").saveAsTable(\"same_zip2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4021da0-0f4b-4331-80fd-2f5c3ce00196",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Directly load a spark table"
    }
   },
   "outputs": [],
   "source": [
    "df_same_zip_new = spark.table(\"same_zip2\")\n",
    "df_same_zip_new.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c92cb1dc-1e3b-4e33-88aa-624445135d0a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write a Python Function to rename a column"
    }
   },
   "outputs": [],
   "source": [
    "# Function to rename a column in a DataFrame\n",
    "def renameColumn(df, oldName, newName):\n",
    "    df = df.withColumnRenamed(oldName, newName)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25155264-8c21-4950-9d91-d5439f7c4149",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call that function"
    }
   },
   "outputs": [],
   "source": [
    "df_same_zip_new = renameColumn(df_same_zip_new, \"long_distance\", \"different_zip\")\n",
    "df_same_zip_new.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bec0b5ae-d6ae-4447-89e4-78d2302a5142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# spark.sql(\"DROP TABLE IF EXISTS same_zip\")\n",
    "# spark.sql(\"DROP TABLE IF EXISTS same_zip2\")\n",
    "# spark.sql(\"DROP TABLE IF EXISTS same_zip_agg\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8795085104570559,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Loading sample data v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
